{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Imports"
      ],
      "metadata": {
        "id": "ihVdtovqMf6e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.metrics.distance import edit_distance\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "import itertools\n",
        "\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "metadata": {
        "id": "Wq4UZ8-dMimF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Les bases: Distance Edit"
      ],
      "metadata": {
        "id": "-OVBShhDM50q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# #plus c'est bas, plus ils sont proches === distance\n",
        "distance_1=edit_distance(\"venir\", \"venir\")\n",
        "distance_2=edit_distance(\"vunar\", \"venir\")\n",
        "print(f\"Distance levenshtein entre 'venir' et 'venir' est {distance_1}\\n\"\n",
        "      f\"Distance levenshtein entre 'vunar' et 'venir' est  {distance_2}\")"
      ],
      "metadata": {
        "id": "iX7WNX27M6r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Essayez avec vos propres mots\n",
        "\n"
      ],
      "metadata": {
        "id": "Owry1lXsDyL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # plus c'est haut, plus ils sont similaires === similarité\n",
        "# distance_1_perc=edit_distance(\"venir\", \"venir\")\n",
        "# distance_2_perc=edit_distance(\"vunar\", \"venir\")\n",
        "print(f\"Distance en pourcentage entre 'venir' et 'venir' est {1 - distance_1_perc / max(len('venir'), len('venir'))}\\n\"\n",
        "      f\"Distance en pourcentage entre 'vunar' et 'venir' est {1 - distance_2_perc / max(len('vunar'), len('venir'))}\")"
      ],
      "metadata": {
        "id": "Jozfgzt1M9kU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Essayez avec vos propres mots\n",
        "#copiez le code dans la cellule précédent; remplacez les deux mots 'venir' et 'vunar' par vos mots\n",
        "\n"
      ],
      "metadata": {
        "id": "gk54TP-yD41K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Essayons plusieurs mots pour voir si nous pouvons obtenir un score de proximté\n",
        "\n",
        "texte1 = \"Je suis convaincu que Dakar reste l'une des plus belles villes d'Afrique\"\n",
        "texte2 = \"Dakar reste les villes les plus attirantes dans le monde\"\n",
        "score = 0\n",
        "mots_differents={}\n",
        "mots_proches={}\n",
        "\n",
        "# Compter le nombre total de comparaisons à effectuer\n",
        "totalité_de_comparaison = len(texte1.split()) * len(texte2.split())\n",
        "\n",
        "for mot1 in texte1.split():\n",
        "    for mot2 in texte2.split():\n",
        "        similarité = 1 - edit_distance(mot1, mot2) / max(len(mot1), len(mot2))\n",
        "        score += similarité\n",
        "        if similarité < 0.7:\n",
        "          mots_differents[mot1]=[mot2]\n",
        "        else:\n",
        "          mots_proches[mot1]=[mot2]\n",
        "\n",
        "# Normaliser le score afin d'avoir une similarité entre 0 et 1\n",
        "score_normalisé = 1- (score / totalité_de_comparaison)\n",
        "print(f\" Les deux textes sont similaires à {round(score_normalisé*100, 2)}%\")"
      ],
      "metadata": {
        "id": "VLi-FY_sDtJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mots_differents #voyons les mots les plus proches"
      ],
      "metadata": {
        "id": "Y-nc_6I9IYF4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mots_proches #voyons les mots les plus distincts"
      ],
      "metadata": {
        "id": "Ww7G6HMEIduk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Vérifions si deux mots sont des cognats"
      ],
      "metadata": {
        "id": "E0dIAQPiEVKP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vérifie_cognacité(mot1,mot2,edit_distance=edit_distance, seuil = 0.7):\n",
        "    # Calculater la distance entre deux mots\n",
        "    distance = edit_distance(mot1.lower(), mot2.lower())\n",
        "    longeur_max = max(len(mot1), len(mot2))\n",
        "\n",
        "    # Calculer la simialrité\n",
        "    similarité = 1 - (distance / longeur_max)\n",
        "\n",
        "    # Definissez un seuil de cognacité\n",
        "\n",
        "    if similarité >= seuil:\n",
        "        return f\"'{mot1}' et '{mot2}' sont probablement des cognats (similarité: {similarité:.2f}).\"\n",
        "    else:\n",
        "        return f\"'{mot1}'et '{mot2}' semblent ne pas être des cognats (similarité: {similarité:.2f}).\""
      ],
      "metadata": {
        "id": "LC2-pYQENBvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vérifie_cognacité(\"aller\", \"alleri\")"
      ],
      "metadata": {
        "id": "-qxMk3fbNfxB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Essayez avec vos propres mots\n",
        "#copiez le code dans la cellule précédent; remplacez les deux mots 'venir' et 'vunar' par vos mots\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bVi2iQq0Ef9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rIXF1Lf5Fyd6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Identification de cognates"
      ],
      "metadata": {
        "id": "CLjtJCR8NnGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#chargez les données\n",
        "!wget --no-check-certificate 'https://drive.google.com/uc?export=download&id=1Rp2NRHc3ZbwG-sEU5kt4126HSVPqyjnZ' -O cognate_data_1.csv"
      ],
      "metadata": {
        "id": "EPqWHehlNoU5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chargons les données\n",
        "df_1=pd.read_csv(\"cognate_data_1.csv\").drop(\"Unnamed: 0\", axis=1)\n",
        "df_1.head()"
      ],
      "metadata": {
        "id": "yQGUDdg_Nr1a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#regardons les données de façon randomisées\n",
        "indices_randomisés = random.sample(range(len(df_1)), 2)\n",
        "lignes_randomisés = df_1.iloc[indices_randomisés]\n",
        "print(lignes_randomisés)"
      ],
      "metadata": {
        "id": "n2MyshqSNt0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment calculer la distance Edit entre plusieurs mots?\n",
        "* prenez chaque mot et son sens\n",
        "* si les deux mots on la même signification\n",
        "* calculer la similarité entre les deux mots\n",
        "* sauvegarder le résultats dans une matrice"
      ],
      "metadata": {
        "id": "rts1wDLNOMvi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Fonction pour calculer distance entre les mots ayant le même sens\n",
        "def calculer_matrice(df, edit_distance=edit_distance):\n",
        "    langues = df[\"Language\"].unique()   #récupérer les langues dans vos données\n",
        "    sens = df[\"Meaning\"].unique()       #récupérer les significations disponible dans vos données\n",
        "    mots = df[\"Word\"].values            #récupérer les mots disponible dans vos données\n",
        "\n",
        "    # Initialiser une matrice de distance avec un  NaN pour les cases vides, qui vous permet de sauvegarder les scores de similarité\n",
        "    nombre_mots = len(mots)\n",
        "    matrice_de_distance = np.full((nombre_mots, nombre_mots), np.nan)\n",
        "\n",
        "    # Dictionaire pour lier chaque mot à son sens\n",
        "    mot_vers_sens = df.set_index(\"Word\")[\"Meaning\"].to_dict()\n",
        "\n",
        "    # Calculer distance entre les mots ayant même sens\n",
        "    for i in range(nombre_mots):\n",
        "        matrice_de_distance[i][i] = 1.0\n",
        "        # le score des diagonals\n",
        "        for j in range(i + 1, nombre_mots):\n",
        "            if mot_vers_sens [mots[i]] == mot_vers_sens [mots[j]]:  # vérification de l'égalité des sens\n",
        "                print(f\"En train de calculer distance entre '{mots[i]}' et '{mots[j]}' (Sens: {mot_vers_sens [mots[i]]})\")\n",
        "\n",
        "                #calculer distance, puis similarité\n",
        "                distance = edit_distance(mots[i], mots[j])\n",
        "                longeur_max = max(len(mots[i]), len(mots[j]))\n",
        "                similarité = 1 - (distance / longeur_max)\n",
        "\n",
        "                #sauvegarder les résultas\n",
        "                matrice_de_distance[i][j] = similarité\n",
        "                matrice_de_distance[j][i] = similarité\n",
        "\n",
        "    return pd.DataFrame(matrice_de_distance, columns=mots, index=mots)"
      ],
      "metadata": {
        "id": "KM5tk6mJNzlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrice_de_distance = calculer_matrice(df_1) #appeler la fonction afin d'avoir le calcul des distances"
      ],
      "metadata": {
        "id": "1NwP5j0BN2CV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "matrice_de_distance.head(5)  #regarder ce à quoi ressemble les distances calculer"
      ],
      "metadata": {
        "id": "Axw7HkmtRHio"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment voir quels mots ont été identifiés comme étant des cognats possibles?\n",
        "* prenez les données de départ\n",
        "* prenez la matrice detenant les scores de similarité\n",
        "* filtrez les scores selon un seuil que vous préferez\n",
        "* en croisant les deux, pour chaque mot, ayant une signification, dans une langue donnée, récupérez le score avec d'autres mots ayant le même sens dans d'autres langues afin de constituer un nouveau ensemble de données"
      ],
      "metadata": {
        "id": "zQWFnnDDSYcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#filtrer les données selon un seuil pour obtenir des cognats\n",
        "def filtrer_distances(df, distance_matrix, seuil=0.7):\n",
        "    données_filtrées = []\n",
        "    nombre_de_mots = len(df)\n",
        "\n",
        "    for i in range(nombre_de_mots):\n",
        "        for j in range(nombre_de_mots):\n",
        "            if i != j and distance_matrix.iloc[i, j] >= seuil:\n",
        "                données_filtrées.append({\n",
        "                    \"Meaning\": df.iloc[i][\"Meaning\"],\n",
        "                    \"Word 1\": df.iloc[i][\"Word\"],\n",
        "                    \"Language 1\": df.iloc[i][\"Language\"],\n",
        "                    \"Word 2\": df.iloc[j][\"Word\"],\n",
        "                    \"Language 2\": df.iloc[j][\"Language\"],\n",
        "                    \"Edit Distance\": distance_matrix.iloc[i, j]\n",
        "                })\n",
        "\n",
        "    return pd.DataFrame(données_filtrées)"
      ],
      "metadata": {
        "id": "tERoajBIN-PG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Créer un dataframe filtré\n",
        "données_filtrées = filtrer_distances(df_1, matrice_de_distance)\n",
        "print(f\"Les données de départ sont au total {len(df_1)}\\nLes cognats sont au nombre total de {len(données_filtrées)}\")"
      ],
      "metadata": {
        "id": "2mp7wLo5OHo4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Comment analyser les résultats obtenus?\n",
        "* vous pouvez regardez de façon randomisée les cognats\n",
        "* vous pouvez récupérer la liste de cognats, l'imprimer, pour ensuite l'inspecter\n",
        "* vous pouvez visualiser des statistiques concernant les résultats obtenus\n",
        "* vous pouvez analyser les mots ayant été detectés comme étant des non-cognats"
      ],
      "metadata": {
        "id": "FR4aDUo4TVNo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#1. visualisation randomisée des résultats"
      ],
      "metadata": {
        "id": "n01ucYJEUPIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "données_filtrées[données_filtrées[\"Meaning\"]==random.choice(données_filtrées[\"Meaning\"].unique())]"
      ],
      "metadata": {
        "id": "sQmzpvvJOKeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#2. Imprimez les résultats pour inspecter les cognats detectés"
      ],
      "metadata": {
        "id": "eSugcX5PON1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#obtenez un dictionnaire de cognats\n",
        "def cognates_par_sens(filtered_df):\n",
        "\n",
        "    cognates_dict = {}\n",
        "\n",
        "    # Itérer à travers les données\n",
        "    for _, ligne in filtered_df.iterrows():\n",
        "        sens = ligne[\"Meaning\"]\n",
        "        cognat_pair = (ligne[\"Word 1\"], ligne[\"Word 2\"], ligne[\"Language 1\"], ligne[\"Language 2\"], ligne[\"Edit Distance\"])\n",
        "\n",
        "        if sens not in cognates_dict:\n",
        "            cognates_dict[sens] = []\n",
        "\n",
        "        cognates_dict[sens].append(cognat_pair)\n",
        "\n",
        "    return cognates_dict"
      ],
      "metadata": {
        "id": "Gym1xa4yOUJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cognats_selon_sens = cognates_par_sens(données_filtrées)\n",
        "\n",
        "# Obtenez liste des cognats\n",
        "for signe, cognats in cognats_selon_sens.items():\n",
        "    print(f\"Sens: {signe}\")\n",
        "    for cogn in cognats:\n",
        "        print(f\"  Mot 1: {cogn[0]}, Langue 1: {cogn[2]}, Mot 2: {cogn[1]}, Langue 2: {cogn[3]}, Distance: {cogn[4]}\")"
      ],
      "metadata": {
        "id": "pcX-U4MHOW4Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3. visualisez des statistiques concernant les cognats detectés"
      ],
      "metadata": {
        "id": "mGTR9ae6URnP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Comptez le nombre de cognats par sens\n",
        "nombre_de_cognats = données_filtrées[\"Meaning\"].value_counts()\n",
        "\n",
        "# tracer une illustration\n",
        "plt.figure(figsize=(12, 6))\n",
        "sns.barplot(x=nombre_de_cognats.index, y=nombre_de_cognats.values/2)\n",
        "plt.title(\"Nombre de cognats par sens\")\n",
        "plt.xlabel(\"Sens\")\n",
        "plt.ylabel(\"Nombre de cognats\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "KgyQyGqNOZ2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "signification = list(cognats_selon_sens.keys())\n",
        "nombre_de_cognats_2 = [len(cognats_selon_sens[sens]) for sens in signification]\n",
        "\n",
        "# Identification des mots les plus fréquents selon signification\n",
        "mot_le_plus_fréquent = []\n",
        "frequences = []\n",
        "\n",
        "for sens, cogns in cognats_selon_sens.items():\n",
        "    # récupérer tout les mots pour ce sens\n",
        "    mots = [pair[0] for pair in cogns] + [pair[1] for pair in cogns]\n",
        "\n",
        "    # Identifier le mot le plus fréquent et sa signification\n",
        "    comptage_mots = Counter(mots)\n",
        "    mot_freq, freq = comptage_mots.most_common(1)[0]\n",
        "\n",
        "    mot_le_plus_fréquent.append(mot_freq)\n",
        "    frequences.append(freq)\n",
        "\n",
        "# tracer le graphique pour le nombre de cognat par signification\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.scatter(signification, nombre_de_cognats_2, color='blue', label=\"Nombre de cognats par signification\")\n",
        "plt.xlabel(\"Signification\")\n",
        "plt.ylabel(\"Nombre de Cognats\")\n",
        "plt.title(\"Nombre de Cognats par Signification\")\n",
        "plt.grid(True)\n",
        "\n",
        "plt.xticks(rotation=90)\n",
        "\n",
        "# tracer le graphique pour le mot le plus frequent par signification\n",
        "plt.scatter(signification, frequences, color='red', label=\"Fréquence du mot le plus disponible\")\n",
        "for i, mot in enumerate(mot_le_plus_fréquent):\n",
        "    plt.annotate(mot, (signification[i], frequences[i]), textcoords=\"offset points\", xytext=(5,5), ha='center', fontsize=9)\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "eq_SBcGrOeHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. analyser les non-cognats"
      ],
      "metadata": {
        "id": "1GThRKz3UiJP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sens_non_cognats=[signification for signification in df_1[\"Meaning\"].unique() if signification not in données_filtrées[\"Meaning\"].unique()]\n",
        "df_1[df_1[\"Meaning\"].isin(sens_non_cognats)]"
      ],
      "metadata": {
        "id": "8l8a0-2ZOjv1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Exercice:\n",
        "* Mettez vous sur Google sheets (https://workspace.google.com/intl/fr/products/sheets/)\n",
        "* Préparez une liste de mots dans deux ou trois langues en respectant le format suivant  ID|Langue|Signification|Mot\n",
        "* Pour avoir des meilleurs résultats, vous pouvez mettre la forme API des mots dans la colonne 'Mot' - vous pouvez aussi utiliser la forme orthographique, puis vous appuyer sur les codes ci-dessous pour convertir et pondérer des formes en API avec de procéder avec la détection des cognats.\n",
        "* Chargez vos données à la place des données utilisées pour la démonstration\n",
        "* Remplacez 'Language' partout dans le code, avec 'Langue'; 'Meaning' avec 'Signification' et 'Word' avec 'Mot'\n",
        "* Essayez d'exécuter les codes afin de detecter les cognats potentiels dans vos données"
      ],
      "metadata": {
        "id": "69lGNxU_VQWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Amélioration de l'algorithme en utilisant des formes en Alphabet Phonétique International"
      ],
      "metadata": {
        "id": "-LURO77_OyIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# créer un tableau des sons avec lieu d'articulation - substituer des formes orthographiques si besoin\n",
        "lieu = {\n",
        "    \"bilabial\": [\"b\", \"p\", \"β\", \"ɸ\", \"m\", \"\", \"\"],\n",
        "    \"alvéolaire\": [\"d\", \"t\", \"z\", \"s\", \"n\", \"l\", \"\"],\n",
        "    \"alvéolaire_2\":[\"\", \"\", \"\", \"\",\"\", \"\", \"r\"],\n",
        "    \"palato-alvéolaire\": [\"\", \"\", \"ʒ\", \"ʃ\", \"\", \"\", \"\"],\n",
        "    \"palatal\": [\"ɟ\", \"c\", \"y\", \"ç\", \"ɲ\", \"\",\"\"],\n",
        "    \"vélar\": [\"ɡ\", \"k\", \"ɣ\", \"x\", \"ŋ\", \"\",\"\"],\n",
        "    \"glottal\": [\"\", \"\", \"ɦ\", \"h\", \"\", \"\",\"\"]\n",
        "}\n",
        "\n",
        "# Definir les modes d'articulation\n",
        "mode = ['occlusive voisée', 'occlusive non-voisée', 'fricative voisée', 'fricative non-voisée', 'nasale', 'latéral', 'latéral']\n",
        "\n",
        "# créer la carte des sons\n",
        "carte_de_sons= pd.DataFrame(lieu, index=mode)\n",
        "carte_de_sons"
      ],
      "metadata": {
        "id": "fQk7wJo5Ozr9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculer la distance entre des sons\n",
        "def calculer_distance(col1, col2, idx1, idx2, son1, son2):\n",
        "\n",
        "    if son1 == son2:  #  sons identiques, retourner 0\n",
        "        return 0\n",
        "    elif col1 == col2:#  sons ayant le même lieux d'articulation, retourner une distance de 0.3\n",
        "        return 0.5\n",
        "    elif idx1 == idx2:# sons ayant différents lieux d'articulation, mais même mode d'articulation, retourner une distance progressive\n",
        "        col_distance = abs(col1 - col2) # Calculer la distance entre deux colonnes et augmente selon éloignment\n",
        "        return min(1, 0.5 + (0.1 * col_distance))\n",
        "    else:              # sont ayant différent lieux d'articulation et mode d'articulation\n",
        "        return 1"
      ],
      "metadata": {
        "id": "k5z8G8TbO2eG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#préparer les pairs des sons\n",
        "sons_paires = {}\n",
        "colonnes = list(carte_de_sons.columns)\n",
        "for (idx1, ligne1), (idx2, ligne2) in itertools.product(carte_de_sons.iterrows(), repeat=2):\n",
        "    for col1, son1 in ligne1.items():\n",
        "        for col2, son2 in ligne2.items():\n",
        "            if son1 and son2:  # ne pas prendre en considération des cellulles vides\n",
        "                paire = tuple(sorted((son1, son2))) # classez les paires pour s'assurer de la non-duplicité des clés dans le dico\n",
        "                if paire not in sons_paires:\n",
        "                    # Calculer les positions des colonnes et lignes pour établir la distance\n",
        "                    col_idx1, col_idx2 = colonnes.index(col1), colonnes.index(col2)\n",
        "                    sons_paires[paire] = calculer_distance(col_idx1, col_idx2, idx1, idx2, son1, son2)"
      ],
      "metadata": {
        "id": "VUkZ4okaO5mt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def levenshtein_avec_coût(mot1, mot2, sons_paires=sons_paires, seuil=0.7):\n",
        "    m, n = len(mot1), len(mot2)\n",
        "    dp = [[0 for _ in range(n + 1)] for _ in range(m + 1)]\n",
        "\n",
        "    for i in range(m + 1):\n",
        "        for j in range(n + 1):\n",
        "            if i == 0:\n",
        "                dp[i][j] = j\n",
        "            elif j == 0:\n",
        "                dp[i][j] = i\n",
        "            else:\n",
        "                # Initializer un coût de substitution\n",
        "                coût_de_similarité = 1  # coût par défaut si probabilité à priori n'existe pas dans sons_paires\n",
        "\n",
        "                # même sons, pas de coût\n",
        "                if mot1[i - 1] == mot2[j - 1]:\n",
        "                    coût_de_similarité = 0\n",
        "                else:\n",
        "                    # différents sons; récupérer probabilités de sons_paires\n",
        "                    coût_de_similarité = sons_paires.get((mot1[i - 1], mot2[j - 1]),\n",
        "                                                      sons_paires.get((mot2[j - 1], mot1[i - 1]), 1))\n",
        "\n",
        "                dp[i][j] = min(dp[i - 1][j] + 1,  # suppression\n",
        "                               dp[i][j - 1] + 1,  # insertion\n",
        "                               dp[i - 1][j - 1] + ((coût_de_similarité)/seuil))  # substitution\n",
        "    distance_temp=dp[m][n] #peut dépasser 2\n",
        "\n",
        "    return distance_temp"
      ],
      "metadata": {
        "id": "Uen76iwOO8fJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Résultats sans intégration des connaissances de la linguistique typologique\")\n",
        "print(\"*\" * 70)\n",
        "\n",
        "word_pairs = [(\"addel\", \"atler\"), (\"addel\", \"adhel\"),\n",
        "              (\"addel\", \"athel\"), (\"addel\", \"attel\"),\n",
        "              (\"addel\", \"addel\")]\n",
        "\n",
        "for mot1, mot2 in word_pairs:\n",
        "    print(vérifie_cognacité(mot1, mot2))"
      ],
      "metadata": {
        "id": "trm5pT2qO_AO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Résultats avec intégration des connaissances de la linguistique typologique\")\n",
        "print(\"*\" * 70)\n",
        "for mot1, mot2 in word_pairs:\n",
        "    print(vérifie_cognacité(mot1, mot2, edit_distance=levenshtein_avec_coût))"
      ],
      "metadata": {
        "id": "m6lx4m1gcxwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZMjgGcIxWsn9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}